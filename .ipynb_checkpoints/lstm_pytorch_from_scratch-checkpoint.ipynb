{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import sys\n",
    "import urllib\n",
    "\n",
    "if torch.cuda.is_available(): device = 'cuda'\n",
    "else: device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = urllib.request.urlopen('https://raw.githubusercontent.com/hoanghuy89/rnn-lam-tho-tieng-viet/main/bai_van_mau.txt').read()\n",
    "data = data.decode('utf-8')\n",
    "data = data.lower()\n",
    "chars = list(set(data))\n",
    "\n",
    "char_to_ix = {ch:i for i,ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "datasize, vocab_size =  len(data),  len(chars)\n",
    "\n",
    "hidden_size = 128\n",
    "sequence_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(text, stride = 3):\n",
    "    \"\"\"\n",
    "    Create a training set by scanning a window of size sequence_len over the text corpus, with stride 3.\n",
    "    \"\"\"\n",
    "    text = data\n",
    "    Tx = sequence_len\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(0, len(text) - Tx, stride):\n",
    "        X.append(text[i: i + Tx])\n",
    "        Y.append(text[i + Tx])\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "X, Y = build_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(X, Y):\n",
    "    \"\"\"\n",
    "    Convert X and Y (lists or chars) into pytorch tensor to be given to a recurrent neural network.\n",
    "    \"\"\"\n",
    "    m = len(X)\n",
    "    \n",
    "\n",
    "    x = np.zeros((sequence_len, vocab_size, m))\n",
    "    y = np.zeros((m))\n",
    "    for i, sentence in enumerate(X):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[t, char_to_ix[char], i] = 1\n",
    "        y[i] = char_to_ix[Y[i]]\n",
    "        \n",
    "    x = torch.Tensor(x).to(device)\n",
    "    y = torch.LongTensor(y).to(device)\n",
    "    return x, y\n",
    "\n",
    "# test vectorization\n",
    "x,y = vectorization(X[:10],Y[:10])\n",
    "x.shape,y.shape, 'sequence_len, vocab_size, batch_size'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_lstm_parameters():\n",
    "    \"\"\"\n",
    "    Initialize parameters with small random values\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        b --  Bias, numpy array of shape (n_a, 1)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    Wf = torch.randn(hidden_size, vocab_size + hidden_size, device=device)*0.01 \n",
    "    bf = torch.zeros((hidden_size, 1), requires_grad=True, device=device)\n",
    "    Wu = torch.randn(hidden_size, vocab_size + hidden_size, device=device)*0.01 \n",
    "    bu = torch.zeros((hidden_size, 1), requires_grad=True, device=device)\n",
    "    Wcc = torch.randn(hidden_size, vocab_size + hidden_size, device=device)*0.01 \n",
    "    bcc = torch.zeros((hidden_size, 1), requires_grad=True, device=device)\n",
    "    Wo = torch.randn(hidden_size, vocab_size + hidden_size, device=device)*0.01\n",
    "    bo = torch.zeros((hidden_size, 1), requires_grad=True, device=device)\n",
    "    Wy = torch.randn(vocab_size, hidden_size, device=device)*0.01\n",
    "    by = torch.zeros((vocab_size, 1), requires_grad=True, device=device)\n",
    "    \n",
    "    Wf.requires_grad = True\n",
    "    Wu.requires_grad = True\n",
    "    Wcc.requires_grad = True\n",
    "    Wo.requires_grad = True\n",
    "    Wy.requires_grad = True\n",
    "    \n",
    "    \n",
    "    parameters = [Wf, bf, Wu, bu, Wcc, bcc, Wo, bo, Wy, by]\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "# test init paramter\n",
    "parameters = initialize_lstm_parameters()\n",
    "parameters[1].device, parameters[1].is_leaf, parameters[1].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_step_forward(x, a_prev, c_prev, parameters):\n",
    "    Wf, bf, Wu, bu, Wcc, bcc, Wo, bo, Wy, by = parameters\n",
    "  \n",
    "    concat = torch.cat((a_prev, x),axis=0)\n",
    "\n",
    "    f = torch.sigmoid(Wf @ concat + bf)\n",
    "    u = torch.sigmoid(Wu @ concat + bu)\n",
    "    cc = torch.tanh(Wcc @ concat + bcc)\n",
    "    o = torch.sigmoid(Wo @ concat + bo)\n",
    "\n",
    "\n",
    "    c = f*c_prev + u*cc\n",
    "    a = o*torch.tanh(c)\n",
    "#     y = Wy @ a + by\n",
    "#     return y, a, c\n",
    "    return a, c\n",
    "\n",
    "# test forward step\n",
    "parameters = initialize_lstm_parameters()\n",
    "batch_len=100\n",
    "a_prev = torch.randn((hidden_size,batch_len)).to(device)\n",
    "c_prev = torch.randn((hidden_size,batch_len)).to(device)\n",
    "x = torch.zeros((vocab_size, batch_len)).to(device)\n",
    "a, c = lstm_step_forward(x, a_prev, c_prev, parameters)\n",
    "a.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_forward(batch_X, a_prev, c_prev, parameters):\n",
    "    Wf, bf, Wu, bu, Wcc, bcc, Wo, bo, Wy, by = parameters\n",
    "    batch_size = batch_X.shape[-1]\n",
    "\n",
    "    a = torch.zeros((sequence_len+1, hidden_size, batch_size)).to(device)\n",
    "    c = torch.zeros((sequence_len+1, hidden_size, batch_size)).to(device)\n",
    "    a[0] = a_prev\n",
    "    c[0] = c_prev\n",
    "   \n",
    "    for t in range(sequence_len):\n",
    "        a[t+1], c[t+1] = lstm_step_forward(batch_X[t], a[t].clone(), c[t].clone(), parameters)\n",
    "    y_hat = Wy @ a[t+1].clone() + by\n",
    "    \n",
    "    # loss = torch.sum(-y*torch.log(y_hat))\n",
    "    return y_hat, a[-1].detach(), c[-1].detach()\n",
    "\n",
    "# test forward operation\n",
    "parameters = initialize_lstm_parameters()\n",
    "m=10\n",
    "x,y = vectorization(X[:m],Y[:m])\n",
    "a_prev = torch.randn((hidden_size,m)).to(device)\n",
    "c_prev = torch.randn((hidden_size,m)).to(device)\n",
    "for i in range(10):\n",
    "    y_hat, a_prev, c_prev = lstm_forward(x, a_prev, c_prev, parameters)\n",
    "a_prev.shape, c_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pickle_compress(file_path, data=None, operation='load'):\n",
    "    import bz2\n",
    "    import pickle\n",
    "    import _pickle as cPickle\n",
    "    \n",
    "    a = None\n",
    "    if operation != 'load':\n",
    "        with bz2.BZ2File(file_path, 'wb') as f:\n",
    "            cPickle.dump(data, f)\n",
    "    else:\n",
    "        with bz2.BZ2File(file_path, 'rb') as f:\n",
    "            a = cPickle.load(f)\n",
    "    return a\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64').reshape(-1)\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "   \n",
    "    out = np.random.choice(range(vocab_size), p = preds.ravel())\n",
    "    return out\n",
    "#     return np.argmax(preds)\n",
    "\n",
    "def softmax1d(x):\n",
    "    max, _ = torch.max(x, dim=0, keepdims=True) #returns max of each row and keeps same dims\n",
    "    e_x = torch.exp(x - max) #subtracts each row with its max value\n",
    "    sum = torch.sum(e_x, dim=0, keepdims=True) #returns sum of each row and keeps same dims\n",
    "    sf = e_x / sum \n",
    "\n",
    "    \n",
    "    return sf\n",
    "\n",
    "def generate_output(parameters, get_input=False):\n",
    "    '''\n",
    "    Generate n samples characters with random or set input\n",
    "    '''\n",
    "    generated = ''\n",
    "    m = len(X)\n",
    "    a_prev = torch.randn((hidden_size,1)).to(device)\n",
    "    c_prev = torch.randn((hidden_size,1)).to(device)\n",
    "    if get_input == False:\n",
    "        idx = int(np.random.choice(range(m),1))\n",
    "        sentence = [X[idx]]\n",
    "        Y_sample = [Y[idx]]\n",
    "    else:\n",
    "        usr_input = input(\"Viết câu đầu tiên, ít hơn 40 kí tự: \")\n",
    "        sentence = [('{0:0>' + str(sequence_len) + '}').format(usr_input[:-2]).lower()]\n",
    "        generated += usr_input\n",
    "        Y_sample = [usr_input[-1]]\n",
    "#         print(sentence, len(sentence[0]))\n",
    "    \n",
    "    for i in range(1000):\n",
    "        x , y = vectorization(sentence, Y_sample)\n",
    "        preds, a_prev, c_prev = lstm_forward(x, a_prev, c_prev, parameters)\n",
    "        preds = softmax1d(preds)\n",
    "        next_index = sample(preds.detach().cpu(), temperature = .5)\n",
    "            \n",
    "        next_char = ix_to_char[next_index]\n",
    "            \n",
    "        generated += next_char\n",
    "        sentence = [sentence[0][1:] + next_char]\n",
    "        \n",
    "    return generated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    m = len(X)\n",
    "    batch_size = 1000\n",
    "    num_batch = np.floor(m/batch_size)\n",
    "    num_iterations = 20\n",
    "    if 'parameters' not in locals():\n",
    "        parameters = initialize_lstm_parameters()\n",
    "    a_prev = torch.randn((hidden_size,batch_size)).to(device)\n",
    "    c_prev = torch.randn((hidden_size,batch_size)).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(parameters, lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        loss_total = 0\n",
    "        permutation = np.random.permutation(m)\n",
    "        count = 0\n",
    "\n",
    "        for j in range(0,m,batch_size):\n",
    "            indices = permutation[j:j+batch_size]\n",
    "            if len(indices) == batch_size: # skip last batch if m%batch_size!=0\n",
    "                batch_X, batch_Y = [X[i] for i in indices], [Y[i] for i in indices] # mini batch\n",
    "                batch_X, batch_Y = vectorization(batch_X, batch_Y)\n",
    "\n",
    "                y_hat, a_prev, c_prev =  lstm_forward(batch_X, a_prev, c_prev, parameters)\n",
    "                loss = criterion(y_hat.T, batch_Y)\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_value_(parameters, 1)\n",
    "                optimizer.step()    # Does the update\n",
    "                optimizer.zero_grad()\n",
    "                count+=1\n",
    "                loss_total += loss.detach()\n",
    "        pickle_compress('params.pickle', parameters, 'write')\n",
    "        print('\\nIteration: %d, Loss: %f' % (i, loss_total/num_batch) + '\\n')\n",
    "        print(generate_output(parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 0, Loss: 2.267718\n",
      "\n",
      " là nghệ thuyến lại chửa của chánh thể những đấy những nhưng nhiều làm thái thân đất như trong đã cho bắc đất những trên, nhất cho việt cho những những thực sác đàng đã chuyện nhớ núi là những thấy những cho những cho cách sống thẳng những những trinh thuyến là hơi thay xa mặt một trần đã đi chỉ về thật ngoài chay chúng một đi thấy những chịu vành những một nghệ làng trong một chân nghĩa gian cho cho chiều chiến chăng trơn thay vào đói bài cho đến thường làm chi chúng có những thải qua học doài những chỉ chiếc thái hai chồng thê trường chư chiến đã đất nhắt trong nhưng cảnh thế diện chúng thấy trị trên nghệ tháng chiếc những cho nhà cho chiều cho lên trong thác phải cảnh thể đã chịu những phác và quan trường trong trường nước sắc một nhưng thấy đi truyện chỉ là chiến tráng cho chịu cho, trước choa đại vào đầy chịu sự nhà nên bài những nhác con ngặn thế những chúng những thải chú thể hịnh một phải trên dài con thần người là nhà những những con nghệ thái tác khác lào phải những đã chiếc \n",
      "\n",
      "Iteration: 1, Loss: 1.786768\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-96e850ef03fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mgenerated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msample_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-96e850ef03fb>\u001b[0m in \u001b[0;36msample_network\u001b[1;34m(istrain)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msample_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mistrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mistrain\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_compress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params.pickle'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# load params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-b460cf0d35a6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mpickle_compress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nIteration: %d, Loss: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_total\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-1b6446de1119>\u001b[0m in \u001b[0;36mgenerate_output\u001b[1;34m(parameters, get_input)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mnext_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-6e632844c46c>\u001b[0m in \u001b[0;36mlstm_forward\u001b[1;34m(batch_X, a_prev, c_prev, parameters)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm_step_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWy\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-8887161d7957>\u001b[0m in \u001b[0;36mlstm_step_forward\u001b[1;34m(x, a_prev, c_prev, parameters)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mWf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWf\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mconcat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = pickle_compress('params.pickle')\n",
    "def sample_network(istrain=False):\n",
    "    if istrain == True:\n",
    "        train()\n",
    "    else:\n",
    "        parameters = pickle_compress('params.pickle') # load params\n",
    "        generated = generate_output(parameters, True)\n",
    "        print(generated)\n",
    "sample_network(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
