{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('bai_van_mau.txt','r',encoding='utf-8').read()\n",
    "data = data.replace('\\n', ' ').lower()\n",
    "chars = list(set(data))\n",
    "sents = sent_tokenize(data)\n",
    "sents = [sent.replace('.','') for sent in sents]\n",
    "\n",
    "char_to_ix = {ch:i for i,ch in enumerate(chars)}\n",
    "ix_to_char = {i:ch for i,ch in enumerate(chars)}\n",
    "datasize, sents_size, vocab_size =  len(data), len(sents), len(chars)\n",
    "datasize, sents_size, vocab_size\n",
    "max_str_len = len(max(sents,key=len))\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_a, n_x, n_y):\n",
    "    \"\"\"\n",
    "    Initialize parameters with small random values\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing:\n",
    "                        Wax -- Weight matrix multiplying the input, numpy array of shape (n_a, n_x)\n",
    "                        Waa -- Weight matrix multiplying the hidden state, numpy array of shape (n_a, n_a)\n",
    "                        Wya -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_y, n_a)\n",
    "                        b --  Bias, numpy array of shape (n_a, 1)\n",
    "                        by -- Bias relating the hidden-state to the output, numpy array of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    Wax = torch.randn(n_a, n_x)*0.01 # input to hidden\n",
    "    Waa = torch.randn(n_a, n_a)*0.01 # hidden to hidden\n",
    "    Wya = torch.randn(n_y, n_a)*0.01 # hidden to output\n",
    "    b = torch.zeros((n_a, 1), requires_grad=True) # hidden bias\n",
    "    by = torch.zeros((n_y, 1), requires_grad=True) # output bias\n",
    "    \n",
    "    Wax.requires_grad=True\n",
    "    Waa.requires_grad=True\n",
    "    Wya.requires_grad=True\n",
    "    \n",
    "    parameters = [Wax, Waa, Wya, b, by]\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "# test init paramter\n",
    "parameters = initialize_parameters(50, vocab_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4397],\n",
       "        [0.0908],\n",
       "        [0.0950],\n",
       "        [0.3745]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax1d(x):\n",
    "    max, _ = torch.max(x, dim=0, keepdims=True) #returns max of each row and keeps same dims\n",
    "    e_x = torch.exp(x - max) #subtracts each row with its max value\n",
    "    sum = torch.sum(e_x, dim=0, keepdims=True) #returns sum of each row and keeps same dims\n",
    "    sf = e_x / sum \n",
    "\n",
    "    return sf\n",
    "# test\n",
    "a = torch.randn(4,1)\n",
    "softmax1d(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(sample_ix):\n",
    "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "    txt = txt[0].upper() + txt[1:]  # capitalize first character \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1]), torch.Size([136, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rnn_step_forward(parameters, a_prev, x):\n",
    "    Wax, Waa, Wya, b, by = parameters\n",
    "    a = torch.tanh(Wax @ x + Waa@ a_prev + b)\n",
    "    z = Wya @ a + by\n",
    "#     y = softmax1d(z)\n",
    "    \n",
    "    return a, z\n",
    "\n",
    "# check\n",
    "a_prev = torch.zeros((n_a,1))\n",
    "x = torch.zeros((vocab_size, 1))\n",
    "a, y = rnn_step_forward(parameters, a_prev, x)\n",
    "a.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  1,\n",
       "  93,\n",
       "  27,\n",
       "  10,\n",
       "  29,\n",
       "  87,\n",
       "  36,\n",
       "  13,\n",
       "  69,\n",
       "  50,\n",
       "  114,\n",
       "  47,\n",
       "  98,\n",
       "  107],\n",
       " 201,\n",
       " 'Pàứ;ộ*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-*iṣậ2ỏeoyịã-.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample(parameters, maxlength=200):\n",
    "    \"\"\"\n",
    "    Sample a sequence of characters according to a sequence of probability distributions output of the RNN\n",
    "   \"\"\"\n",
    "    \n",
    "    # Retrieve parameters and relevant shapes from \"parameters\" dictionary\n",
    "    Waa, Wax, Wya, by, b = parameters\n",
    "    n_y, n_a = Wya.shape\n",
    "\n",
    "    x = torch.zeros((vocab_size, 1))\n",
    "    x[np.random.randint(0,vocab_size)] = 1\n",
    "    a_prev = torch.zeros((n_a,1))\n",
    "    \n",
    "    indices = []\n",
    "    idx = -1 \n",
    "    \n",
    "    counter = 0\n",
    "    newline_character = char_to_ix['.']\n",
    "    \n",
    "    while (idx != newline_character and counter != maxlength):\n",
    "        a_prev, y = rnn_step_forward(parameters, a_prev, x)\n",
    "        y = softmax1d(y)\n",
    "        y_local = y.detach().numpy()\n",
    "        \n",
    "#         idx = np.random.choice(range(len(y_local)), p=y_local.reshape(-1))\n",
    "        idx = np.argmax(y_local)\n",
    "        indices.append(idx)\n",
    "        \n",
    "        # one hot vector\n",
    "        x = torch.zeros((vocab_size, 1))\n",
    "        x[idx] = 1\n",
    "       \n",
    "        counter +=1\n",
    "\n",
    "    if (counter == maxlength):\n",
    "        indices.append(char_to_ix['.'])\n",
    "    \n",
    "    return indices\n",
    "\n",
    "# test sample\n",
    "n_a, n_x, n_y = 50, vocab_size, vocab_size\n",
    "parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "sample(parameters), len(sample(parameters)), get_sample(sample(parameters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2746b867888>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([297, 136, 1]), torch.Size([50, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rnn_forward(X, Y, a0, parameters):\n",
    "    # X n_x, m, t_x\n",
    "    # t_x = max_str_len\n",
    "    # Initialize x, a and y_hat as empty dictionaries\n",
    "    sequence_len = len(X)\n",
    "    x = torch.zeros((sequence_len, vocab_size, 1))\n",
    "    y_hat = torch.zeros((sequence_len, vocab_size, 1))\n",
    "    y = torch.zeros((sequence_len, vocab_size, 1))\n",
    "    # initialize your loss to 0\n",
    "    a = torch.zeros((sequence_len+1, n_a, 1))\n",
    "    a[0] = a0.detach()\n",
    "    loss = torch.zeros(1)\n",
    "    for t in range(sequence_len):\n",
    "        # Set x[t] to be the one-hot vector representation of the t'th character in X.\n",
    "        # if X[t] == None, we just have x[t]=0. This is used to set the input for the first timestep to the zero vector. \n",
    "        \n",
    "        if (X[t] != None):\n",
    "            x[t][X[t],0] = 1\n",
    "        y[t][Y[t]] = 1\n",
    "\n",
    "    for t in range(0,sequence_len):\n",
    "        # Run one step forward of the RNN\n",
    "        a[t+1], y_hat[t] = rnn_step_forward(parameters, a[t].clone(), x[t])\n",
    "        \n",
    "    # Update the loss by substracting the cross-entropy term of this time-step from it.\n",
    "    # loss = torch.sum(-y*torch.log(y_hat))\n",
    "        \n",
    "    return y_hat, a[-1]\n",
    "\n",
    "# test rnn_forward\n",
    "single_example = sents[0]\n",
    "single_example_chars = [c for c in single_example]\n",
    "single_example_ix = [char_to_ix[c] for c in single_example_chars]\n",
    "\n",
    "X = [None]+single_example_ix\n",
    "ix_newline = char_to_ix['.']\n",
    "Y = X[1:] + [ix_newline]\n",
    "a_prev = torch.zeros((n_a, 1))\n",
    "y_hat, a = rnn_forward(X, Y, a_prev, parameters)\n",
    "y_hat.shape, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimize(X, Y, a_prev, parameters, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Execute one step of the optimization to train the model.\n",
    "    \"\"\"\n",
    "    # Forward propagate through time (≈1 line)\n",
    "\n",
    "    y_hat, a_prev =  rnn_forward(X, Y, a_prev, parameters)\n",
    "    loss = criterion(y_hat.reshape(-1,vocab_size), torch.LongTensor(Y))\n",
    "    loss.backward()\n",
    "    \n",
    "#     Clip your gradients between -5 (min) and 5 (max) (≈1 line)\n",
    "    torch.nn.utils.clip_grad_value_(parameters, 5)\n",
    "    \n",
    "#     Update parameters (≈1 line)\n",
    "    optimizer.step()    # Does the update\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return loss, a_prev\n",
    "\n",
    "# test optimize \n",
    "parameters = initialize_parameters(n_a, vocab_size, vocab_size)\n",
    "\n",
    "single_example = sents[0]\n",
    "single_example_chars = [c for c in single_example]\n",
    "single_example_ix = [char_to_ix[c] for c in single_example_chars]\n",
    "\n",
    "X = [None]+single_example_ix\n",
    "ix_newline = char_to_ix['.']\n",
    "Y = X[1:] + [ix_newline]\n",
    "optimizer = optim.Adam(parameters, lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "a_prev = torch.zeros((n_a, 1))\n",
    "for i in range(2):\n",
    "    loss, a_prev = optimize(X, Y, a_prev, parameters, optimizer, criterion)\n",
    "a_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 136])\n",
      "torch.Size([50, 50])\n",
      "torch.Size([136, 50])\n",
      "torch.Size([50, 1])\n",
      "torch.Size([136, 1])\n",
      "bài làm  sau kì kiểm tra giữa học kì hai lớp ba, lớp em được nhà trường tổ chức đưa đi tham quan gian viện bảo tàng thành phố  X =  [None, 55, 123, 87, 40, 135, 123, 53, 40, 40, 36, 33, 127, 40, 22, 72, 40, 22, 87, 97, 53, 40, 12, 92, 33, 40, 39, 87, 32, 33, 40, 104, 59, 64, 40, 22, 72, 40, 104, 33, 87, 40, 135, 91, 128, 40, 55, 33, 67, 40, 135, 91, 128, 40, 47, 53, 40, 83, 111, 103, 64, 40, 96, 104, 123, 40, 12, 92, 111, 118, 96, 39, 40, 12, 14, 40, 64, 104, 77, 64, 40, 83, 111, 33, 40, 83, 87, 40, 12, 104, 33, 53, 40, 88, 127, 33, 96, 40, 39, 87, 33, 96, 40, 20, 87, 26, 96, 40, 55, 70, 98, 40, 12, 123, 96, 39, 40, 12, 104, 123, 96, 104, 40, 128, 104, 44] \n",
      " Y =        [55, 123, 87, 40, 135, 123, 53, 40, 40, 36, 33, 127, 40, 22, 72, 40, 22, 87, 97, 53, 40, 12, 92, 33, 40, 39, 87, 32, 33, 40, 104, 59, 64, 40, 22, 72, 40, 104, 33, 87, 40, 135, 91, 128, 40, 55, 33, 67, 40, 135, 91, 128, 40, 47, 53, 40, 83, 111, 103, 64, 40, 96, 104, 123, 40, 12, 92, 111, 118, 96, 39, 40, 12, 14, 40, 64, 104, 77, 64, 40, 83, 111, 33, 40, 83, 87, 40, 12, 104, 33, 53, 40, 88, 127, 33, 96, 40, 39, 87, 33, 96, 40, 20, 87, 26, 96, 40, 55, 70, 98, 40, 12, 123, 96, 39, 40, 12, 104, 123, 96, 104, 40, 128, 104, 44, 107] \n",
      "\n",
      "đương nhiên, cùng với việc chú trọng nội dung nhưng chúng ta cũng không nên xem nhẹ hình thức, bởi hình thức phần nào phản ánh nội dung  X =  [None, 83, 111, 2, 96, 39, 40, 96, 104, 87, 6, 96, 67, 40, 64, 117, 96, 39, 40, 20, 91, 87, 40, 20, 87, 26, 64, 40, 64, 104, 15, 40, 12, 92, 59, 96, 39, 40, 96, 132, 87, 40, 4, 127, 96, 39, 40, 96, 104, 111, 96, 39, 40, 64, 104, 15, 96, 39, 40, 12, 33, 40, 64, 126, 96, 39, 40, 22, 104, 68, 96, 39, 40, 96, 6, 96, 40, 17, 47, 53, 40, 96, 104, 41, 40, 104, 72, 96, 104, 40, 12, 104, 77, 64, 67, 40, 55, 110, 87, 40, 104, 72, 96, 104, 40, 12, 104, 77, 64, 40, 128, 104, 24, 96, 40, 96, 123, 98, 40, 128, 104, 70, 96, 40, 38, 96, 104, 40, 96, 132, 87, 40, 4, 127, 96, 39] \n",
      " Y =        [83, 111, 2, 96, 39, 40, 96, 104, 87, 6, 96, 67, 40, 64, 117, 96, 39, 40, 20, 91, 87, 40, 20, 87, 26, 64, 40, 64, 104, 15, 40, 12, 92, 59, 96, 39, 40, 96, 132, 87, 40, 4, 127, 96, 39, 40, 96, 104, 111, 96, 39, 40, 64, 104, 15, 96, 39, 40, 12, 33, 40, 64, 126, 96, 39, 40, 22, 104, 68, 96, 39, 40, 96, 6, 96, 40, 17, 47, 53, 40, 96, 104, 41, 40, 104, 72, 96, 104, 40, 12, 104, 77, 64, 67, 40, 55, 110, 87, 40, 104, 72, 96, 104, 40, 12, 104, 77, 64, 40, 128, 104, 24, 96, 40, 96, 123, 98, 40, 128, 104, 70, 96, 40, 38, 96, 104, 40, 96, 132, 87, 40, 4, 127, 96, 39, 107] \n",
      "\n",
      "\n",
      "Iteration: 1, Loss: 4.897784\n",
      "\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      "cô giáo em tươi tắn, gọn gàng trong bộ đồ thể thao, cô tươi cười động viên các bạn còn e lệ nhút nhát xung phong hát giúp vui  X =  [None, 64, 68, 40, 39, 87, 38, 98, 40, 47, 53, 40, 12, 111, 2, 87, 40, 12, 108, 96, 67, 40, 39, 59, 96, 40, 39, 123, 96, 39, 40, 12, 92, 98, 96, 39, 40, 55, 132, 40, 83, 99, 40, 12, 104, 97, 40, 12, 104, 33, 98, 67, 40, 64, 68, 40, 12, 111, 2, 87, 40, 64, 111, 118, 87, 40, 83, 132, 96, 39, 40, 20, 87, 6, 96, 40, 64, 38, 64, 40, 55, 37, 96, 40, 64, 105, 96, 40, 47, 40, 135, 26, 40, 96, 104, 15, 12, 40, 96, 104, 38, 12, 40, 17, 127, 96, 39, 40, 128, 104, 98, 96, 39, 40, 104, 38, 12, 40, 39, 87, 15, 128, 40, 20, 127, 87] \n",
      " Y =        [64, 68, 40, 39, 87, 38, 98, 40, 47, 53, 40, 12, 111, 2, 87, 40, 12, 108, 96, 67, 40, 39, 59, 96, 40, 39, 123, 96, 39, 40, 12, 92, 98, 96, 39, 40, 55, 132, 40, 83, 99, 40, 12, 104, 97, 40, 12, 104, 33, 98, 67, 40, 64, 68, 40, 12, 111, 2, 87, 40, 64, 111, 118, 87, 40, 83, 132, 96, 39, 40, 20, 87, 6, 96, 40, 64, 38, 64, 40, 55, 37, 96, 40, 64, 105, 96, 40, 47, 40, 135, 26, 40, 96, 104, 15, 12, 40, 96, 104, 38, 12, 40, 17, 127, 96, 39, 40, 128, 104, 98, 96, 39, 40, 104, 38, 12, 40, 39, 87, 15, 128, 40, 20, 127, 87, 107] \n",
      "\n",
      "hôm ấy, cái cặp tỏa ra mùi thơm và có tiếng nói thì thầm, yêu thương, trìu mến  X =  [None, 104, 68, 53, 40, 84, 1, 67, 40, 64, 38, 87, 40, 64, 61, 128, 40, 12, 114, 33, 40, 92, 33, 40, 53, 117, 87, 40, 12, 104, 2, 53, 40, 20, 123, 40, 64, 130, 40, 12, 87, 73, 96, 39, 40, 96, 130, 87, 40, 12, 104, 72, 40, 12, 104, 24, 53, 67, 40, 1, 6, 127, 40, 12, 104, 111, 2, 96, 39, 67, 40, 12, 92, 72, 127, 40, 53, 73, 96] \n",
      " Y =        [104, 68, 53, 40, 84, 1, 67, 40, 64, 38, 87, 40, 64, 61, 128, 40, 12, 114, 33, 40, 92, 33, 40, 53, 117, 87, 40, 12, 104, 2, 53, 40, 20, 123, 40, 64, 130, 40, 12, 87, 73, 96, 39, 40, 96, 130, 87, 40, 12, 104, 72, 40, 12, 104, 24, 53, 67, 40, 1, 6, 127, 40, 12, 104, 111, 2, 96, 39, 67, 40, 12, 92, 72, 127, 40, 53, 73, 96, 107] \n",
      "\n",
      "phùng đã phát hiện ra những vẻ đẹp khác ẩn chứa đằng sau những bức ảnh và anh đã bỏ nhiều công sức mới chụp được  X =  [None, 128, 104, 117, 96, 39, 40, 83, 27, 40, 128, 104, 38, 12, 40, 104, 87, 26, 96, 40, 92, 33, 40, 96, 104, 32, 96, 39, 40, 20, 54, 40, 83, 41, 128, 40, 22, 104, 38, 64, 40, 42, 96, 40, 64, 104, 77, 33, 40, 83, 115, 96, 39, 40, 36, 33, 127, 40, 96, 104, 32, 96, 39, 40, 55, 77, 64, 40, 70, 96, 104, 40, 20, 123, 40, 33, 96, 104, 40, 83, 27, 40, 55, 114, 40, 96, 104, 87, 8, 127, 40, 64, 68, 96, 39, 40, 36, 77, 64, 40, 53, 91, 87, 40, 64, 104, 94, 128, 40, 83, 111, 103, 64] \n",
      " Y =        [128, 104, 117, 96, 39, 40, 83, 27, 40, 128, 104, 38, 12, 40, 104, 87, 26, 96, 40, 92, 33, 40, 96, 104, 32, 96, 39, 40, 20, 54, 40, 83, 41, 128, 40, 22, 104, 38, 64, 40, 42, 96, 40, 64, 104, 77, 33, 40, 83, 115, 96, 39, 40, 36, 33, 127, 40, 96, 104, 32, 96, 39, 40, 55, 77, 64, 40, 70, 96, 104, 40, 20, 123, 40, 33, 96, 104, 40, 83, 27, 40, 55, 114, 40, 96, 104, 87, 8, 127, 40, 64, 68, 96, 39, 40, 36, 77, 64, 40, 53, 91, 87, 40, 64, 104, 94, 128, 40, 83, 111, 103, 64, 107] \n",
      "\n",
      "bài 2 vào tiết sinh hoạt lớp cuối tuần, tổ của chúng em sau khi đã thảo luận sôi nổi về những việc cần làm để bảo vệ môi trường  X =  [None, 55, 123, 87, 40, 50, 40, 20, 123, 98, 40, 12, 87, 73, 12, 40, 36, 87, 96, 104, 40, 104, 98, 37, 12, 40, 135, 91, 128, 40, 64, 127, 44, 87, 40, 12, 127, 24, 96, 67, 40, 12, 14, 40, 64, 48, 33, 40, 64, 104, 15, 96, 39, 40, 47, 53, 40, 36, 33, 127, 40, 22, 104, 87, 40, 83, 27, 40, 12, 104, 70, 98, 40, 135, 127, 69, 96, 40, 36, 68, 87, 40, 96, 14, 87, 40, 20, 8, 40, 96, 104, 32, 96, 39, 40, 20, 87, 26, 64, 40, 64, 24, 96, 40, 135, 123, 53, 40, 83, 97, 40, 55, 70, 98, 40, 20, 26, 40, 53, 68, 87, 40, 12, 92, 111, 118, 96, 39] \n",
      " Y =        [55, 123, 87, 40, 50, 40, 20, 123, 98, 40, 12, 87, 73, 12, 40, 36, 87, 96, 104, 40, 104, 98, 37, 12, 40, 135, 91, 128, 40, 64, 127, 44, 87, 40, 12, 127, 24, 96, 67, 40, 12, 14, 40, 64, 48, 33, 40, 64, 104, 15, 96, 39, 40, 47, 53, 40, 36, 33, 127, 40, 22, 104, 87, 40, 83, 27, 40, 12, 104, 70, 98, 40, 135, 127, 69, 96, 40, 36, 68, 87, 40, 96, 14, 87, 40, 20, 8, 40, 96, 104, 32, 96, 39, 40, 20, 87, 26, 64, 40, 64, 24, 96, 40, 135, 123, 53, 40, 83, 97, 40, 55, 70, 98, 40, 20, 26, 40, 53, 68, 87, 40, 12, 92, 111, 118, 96, 39, 107] \n",
      "\n",
      "mụ phủ phục, lạy lấy lạy để vô cùng đáng thương: “con lấy quý tòa” “quý tòa bắt tội con cũng được, phạt tù con cũng được, đừng bắt bỏ nó”  X =  [None, 53, 94, 40, 128, 104, 48, 40, 128, 104, 94, 64, 67, 40, 135, 37, 1, 40, 135, 84, 1, 40, 135, 37, 1, 40, 83, 97, 40, 20, 68, 40, 64, 117, 96, 39, 40, 83, 38, 96, 39, 40, 12, 104, 111, 2, 96, 39, 82, 40, 109, 64, 98, 96, 40, 135, 84, 1, 40, 88, 127, 101, 40, 12, 105, 33, 18, 40, 109, 88, 127, 101, 40, 12, 105, 33, 40, 55, 108, 12, 40, 12, 132, 87, 40, 64, 98, 96, 40, 64, 126, 96, 39, 40, 83, 111, 103, 64, 67, 40, 128, 104, 37, 12, 40, 12, 117, 40, 64, 98, 96, 40, 64, 126, 96, 39, 40, 83, 111, 103, 64, 67, 40, 83, 90, 96, 39, 40, 55, 108, 12, 40, 55, 114, 40, 96, 130, 18] \n",
      " Y =        [53, 94, 40, 128, 104, 48, 40, 128, 104, 94, 64, 67, 40, 135, 37, 1, 40, 135, 84, 1, 40, 135, 37, 1, 40, 83, 97, 40, 20, 68, 40, 64, 117, 96, 39, 40, 83, 38, 96, 39, 40, 12, 104, 111, 2, 96, 39, 82, 40, 109, 64, 98, 96, 40, 135, 84, 1, 40, 88, 127, 101, 40, 12, 105, 33, 18, 40, 109, 88, 127, 101, 40, 12, 105, 33, 40, 55, 108, 12, 40, 12, 132, 87, 40, 64, 98, 96, 40, 64, 126, 96, 39, 40, 83, 111, 103, 64, 67, 40, 128, 104, 37, 12, 40, 12, 117, 40, 64, 98, 96, 40, 64, 126, 96, 39, 40, 83, 111, 103, 64, 67, 40, 83, 90, 96, 39, 40, 55, 108, 12, 40, 55, 114, 40, 96, 130, 18, 107] \n",
      "\n",
      "người đàn bà ngoài bốn mươi tuổi, cao lớn, thô kệch, rỗ mặt, mệt mỏi, tái ngắt người đàn ông đi sau \"lưng rộng và cong như lưng một chiếc thuyền; mái tóc tổ quạ, chân chữ bát, lông mày cháy nắng, rủ xuống\", lão đàn ông con mắt đầy vẻ độc dữ lúc nào cũng nhìn dán vào tấm lưng áo bạc phếch và rách rưới, nửa thân ướt sũng của người đàn bà\"  X =  [None, 96, 39, 111, 118, 87, 40, 83, 123, 96, 40, 55, 123, 40, 96, 39, 98, 123, 87, 40, 55, 44, 96, 40, 53, 111, 2, 87, 40, 12, 127, 14, 87, 67, 40, 64, 33, 98, 40, 135, 91, 96, 67, 40, 12, 104, 68, 40, 22, 26, 64, 104, 67, 40, 92, 86, 40, 53, 61, 12, 67, 40, 53, 26, 12, 40, 53, 114, 87, 67, 40, 12, 38, 87, 40, 96, 39, 108, 12, 40, 96, 39, 111, 118, 87, 40, 83, 123, 96, 40, 68, 96, 39, 40, 83, 87, 40, 36, 33, 127, 40, 76, 135, 111, 96, 39, 40, 92, 132, 96, 39, 40, 20, 123, 40, 64, 98, 96, 39, 40, 96, 104, 111, 40, 135, 111, 96, 39, 40, 53, 132, 12, 40, 64, 104, 87, 73, 64, 40, 12, 104, 127, 1, 8, 96, 121, 40, 53, 38, 87, 40, 12, 130, 64, 40, 12, 14, 40, 88, 127, 37, 67, 40, 64, 104, 106, 96, 40, 64, 104, 32, 40, 55, 38, 12, 67, 40, 135, 68, 96, 39, 40, 53, 123, 1, 40, 64, 104, 38, 1, 40, 96, 108, 96, 39, 67, 40, 92, 48, 40, 17, 127, 44, 96, 39, 76, 67, 40, 135, 27, 98, 40, 83, 123, 96, 40, 68, 96, 39, 40, 64, 98, 96, 40, 53, 108, 12, 40, 83, 24, 1, 40, 20, 54, 40, 83, 132, 64, 40, 4, 32, 40, 135, 15, 64, 40, 96, 123, 98, 40, 64, 126, 96, 39, 40, 96, 104, 72, 96, 40, 4, 38, 96, 40, 20, 123, 98, 40, 12, 84, 53, 40, 135, 111, 96, 39, 40, 38, 98, 40, 55, 37, 64, 40, 128, 104, 73, 64, 104, 40, 20, 123, 40, 92, 38, 64, 104, 40, 92, 111, 91, 87, 67, 40, 96, 133, 33, 40, 12, 104, 106, 96, 40, 111, 91, 12, 40, 36, 126, 96, 39, 40, 64, 48, 33, 40, 96, 39, 111, 118, 87, 40, 83, 123, 96, 40, 55, 123, 76] \n",
      " Y =        [96, 39, 111, 118, 87, 40, 83, 123, 96, 40, 55, 123, 40, 96, 39, 98, 123, 87, 40, 55, 44, 96, 40, 53, 111, 2, 87, 40, 12, 127, 14, 87, 67, 40, 64, 33, 98, 40, 135, 91, 96, 67, 40, 12, 104, 68, 40, 22, 26, 64, 104, 67, 40, 92, 86, 40, 53, 61, 12, 67, 40, 53, 26, 12, 40, 53, 114, 87, 67, 40, 12, 38, 87, 40, 96, 39, 108, 12, 40, 96, 39, 111, 118, 87, 40, 83, 123, 96, 40, 68, 96, 39, 40, 83, 87, 40, 36, 33, 127, 40, 76, 135, 111, 96, 39, 40, 92, 132, 96, 39, 40, 20, 123, 40, 64, 98, 96, 39, 40, 96, 104, 111, 40, 135, 111, 96, 39, 40, 53, 132, 12, 40, 64, 104, 87, 73, 64, 40, 12, 104, 127, 1, 8, 96, 121, 40, 53, 38, 87, 40, 12, 130, 64, 40, 12, 14, 40, 88, 127, 37, 67, 40, 64, 104, 106, 96, 40, 64, 104, 32, 40, 55, 38, 12, 67, 40, 135, 68, 96, 39, 40, 53, 123, 1, 40, 64, 104, 38, 1, 40, 96, 108, 96, 39, 67, 40, 92, 48, 40, 17, 127, 44, 96, 39, 76, 67, 40, 135, 27, 98, 40, 83, 123, 96, 40, 68, 96, 39, 40, 64, 98, 96, 40, 53, 108, 12, 40, 83, 24, 1, 40, 20, 54, 40, 83, 132, 64, 40, 4, 32, 40, 135, 15, 64, 40, 96, 123, 98, 40, 64, 126, 96, 39, 40, 96, 104, 72, 96, 40, 4, 38, 96, 40, 20, 123, 98, 40, 12, 84, 53, 40, 135, 111, 96, 39, 40, 38, 98, 40, 55, 37, 64, 40, 128, 104, 73, 64, 104, 40, 20, 123, 40, 92, 38, 64, 104, 40, 92, 111, 91, 87, 67, 40, 96, 133, 33, 40, 12, 104, 106, 96, 40, 111, 91, 12, 40, 36, 126, 96, 39, 40, 64, 48, 33, 40, 96, 39, 111, 118, 87, 40, 83, 123, 96, 40, 55, 123, 76, 107] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mỗi ngày, chồng ra biển đánh cá thì vợ ởnhà trông con và vá lưới, đan lưới  X =  [None, 53, 86, 87, 40, 96, 39, 123, 1, 67, 40, 64, 104, 99, 96, 39, 40, 92, 33, 40, 55, 87, 97, 96, 40, 83, 38, 96, 104, 40, 64, 38, 40, 12, 104, 72, 40, 20, 103, 40, 110, 96, 104, 123, 40, 12, 92, 68, 96, 39, 40, 64, 98, 96, 40, 20, 123, 40, 20, 38, 40, 135, 111, 91, 87, 67, 40, 83, 33, 96, 40, 135, 111, 91, 87] \n",
      " Y =        [53, 86, 87, 40, 96, 39, 123, 1, 67, 40, 64, 104, 99, 96, 39, 40, 92, 33, 40, 55, 87, 97, 96, 40, 83, 38, 96, 104, 40, 64, 38, 40, 12, 104, 72, 40, 20, 103, 40, 110, 96, 104, 123, 40, 12, 92, 68, 96, 39, 40, 64, 98, 96, 40, 20, 123, 40, 20, 38, 40, 135, 111, 91, 87, 67, 40, 83, 33, 96, 40, 135, 111, 91, 87, 107] \n",
      "\n",
      "ve áo gi-lê đính một ngôi sao bạc, gấu ta ra dáng một cảnh sát trưởng ghê vậy đó  X =  [None, 20, 47, 40, 38, 98, 40, 39, 87, 10, 135, 6, 40, 83, 0, 96, 104, 40, 53, 132, 12, 40, 96, 39, 68, 87, 40, 36, 33, 98, 40, 55, 37, 64, 67, 40, 39, 84, 127, 40, 12, 33, 40, 92, 33, 40, 4, 38, 96, 39, 40, 53, 132, 12, 40, 64, 70, 96, 104, 40, 36, 38, 12, 40, 12, 92, 111, 110, 96, 39, 40, 39, 104, 6, 40, 20, 69, 1, 40, 83, 130] \n",
      " Y =        [20, 47, 40, 38, 98, 40, 39, 87, 10, 135, 6, 40, 83, 0, 96, 104, 40, 53, 132, 12, 40, 96, 39, 68, 87, 40, 36, 33, 98, 40, 55, 37, 64, 67, 40, 39, 84, 127, 40, 12, 33, 40, 92, 33, 40, 4, 38, 96, 39, 40, 53, 132, 12, 40, 64, 70, 96, 104, 40, 36, 38, 12, 40, 12, 92, 111, 110, 96, 39, 40, 39, 104, 6, 40, 20, 69, 1, 40, 83, 130, 107] \n",
      "\n",
      "\n",
      "Iteration: 201, Loss: 3.158251\n",
      "\n",
      "Ng th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      " th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th t.\n",
      "Ng th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th.\n",
      "Th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th.\n",
      "Th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th.\n",
      "Th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th th.\n",
      "\n",
      "Iteration: 401, Loss: 2.407197\n",
      "\n",
      " tha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha.\n",
      "Ời tha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha n.\n",
      " tha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha.\n",
      "Ng tha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha n.\n",
      " tha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha.\n",
      "Ho nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha nha n.\n",
      "Fð̣@@@@̣@@@̣@@@@̣@@@@̣@@@̣@@@̣̣@@@̣@@@@̣@@@̣@@@@̣@@@̣@@@@̣@@@̣@@@@̣@@@@̣@@@̣@@@@̣@@@̣@@@@̣@@@̣@@@@̣@@@@̣@@@̣@@@̣̣@@@̣@@@@̣@@@̣@@@@̣@@@̣@@@@̣@@@̣̣@@@̣@@@@̣@@@̣@@@@̣@@@̣@@@@̣@@@̣@@@@̣@@@@̣@@@̣@@@@̣@@@̣@.\n",
      "\n",
      "Iteration: 601, Loss: 2.275145\n",
      "\n",
      "Hh thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng.\n",
      "Ng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng.\n",
      "C thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng .\n",
      "Ột thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng.\n",
      "C thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng .\n",
      "Jỹặtỹẳngọp jộtð*w'wð•ðwð*ð'ðwð'*ð•ð*ð'*ðwð*ð'ðwðð*ð'ð*ðð*wðw*'ðwð'ð*ðwðwððwð*ð'ððwð*ð'ð*wð*ð'ð*ðð*w'ð*ðwð'ððwð*ð'*ðwð*ð'w*'ð*ð'ð*ððððwðwð*ð'*ð'ð*ð'*ð•ð*ð'ðwðð*ðwðwð*ð'*ðwð*ð'ðð•ð*ð'ðwðð*ð'ð*ðð*wðw*'ð*.\n",
      "H thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng thứng .\n",
      "\n",
      "Iteration: 801, Loss: 2.072797\n",
      "\n",
      " thên thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người th.\n",
      " thên thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người th.\n",
      "Nh thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người t.\n",
      "Hông thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi.\n",
      " thi thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người.\n",
      "Ng thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi t.\n",
      "*ẵ•'’ðọc trên thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi thi người thi .\n",
      "\n",
      "Iteration: 1001, Loss: 1.982568\n",
      "\n",
      "Ến đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã.\n",
      " đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đ.\n",
      " thúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng c.\n",
      " đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đ.\n",
      " đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đã đi đ.\n",
      "M thúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng chúng .\n",
      "Yên vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng vừng v.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 1201, Loss: 2.782294\n",
      "\n",
      " chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chún.\n",
      " như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như .\n",
      "Thiền như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng.\n",
      " như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như .\n",
      " như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như .\n",
      " và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và c.\n",
      "Ị thiến như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chúng như và chú.\n",
      "\n",
      "Iteration: 1401, Loss: 2.109148\n",
      "\n",
      "À cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho ch.\n",
      "M thon cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho c.\n",
      " cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho.\n",
      " cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho.\n",
      "Ẫn cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho c.\n",
      "Ng cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho c.\n",
      " cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho.\n",
      "\n",
      "Iteration: 1601, Loss: 2.249104\n",
      "\n",
      "N thi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi ch.\n",
      " thi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi.\n",
      "Hông chuyện thi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi .\n",
      " chuyện thi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi .\n",
      " chuyện thi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi .\n",
      " hiện thức chuyện thi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi ch.\n",
      " thi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi chi.\n",
      "\n",
      "Iteration: 1801, Loss: 2.418106\n",
      "\n",
      " nhiều như thành thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thà.\n",
      " nhiều như thành thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thà.\n",
      "M thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thà.\n",
      "N thong thành thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn t.\n",
      "N thong thành thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn t.\n",
      "U thành thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn th.\n",
      "Ng thương thành thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn thàn.\n",
      "\n",
      "Iteration: 2001, Loss: 1.845421\n",
      "\n",
      "N chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy .\n",
      " chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy c.\n",
      "Ể chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy .\n",
      "Ch thiếc chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chún.\n",
      " chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy c.\n",
      " chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy c.\n",
      "Ch thiếc chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chúng thầy chún.\n",
      "\n",
      "Iteration: 2201, Loss: 2.162049\n",
      "\n",
      "Ch thế nhà chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư ch.\n",
      " thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư c.\n",
      "C thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư .\n",
      "Êu thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến .\n",
      "I chuyện thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thườ.\n",
      "I thế nhà chuyện thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư chiến thường thư ch.\n",
      " mới người người người người người người người người người người người người người người người người người người người người người người người người người người người người người người người người ngư.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 2401, Loss: 2.179434\n",
      "\n",
      " thương cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũ.\n",
      " cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng cũng.\n",
      " chúc nhiên bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay .\n",
      " cảm bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn.\n",
      "O thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên thiên .\n",
      "Ng là chúc nhiên bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn.\n",
      "A là là lại bàn bàu chúc nhiên bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn bay bàn b.\n",
      "\n",
      "Iteration: 2601, Loss: 1.683816\n",
      "\n",
      " thiếu để chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị ch.\n",
      " những chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị c.\n",
      "Ng chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị c.\n",
      "Rương chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị ch.\n",
      " thơ theo chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị ch.\n",
      "I chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị ch.\n",
      " để thiếu để chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị chị.\n",
      "\n",
      "Iteration: 2801, Loss: 2.017815\n",
      "\n",
      "Y người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi .\n",
      "I thổ như thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổ.\n",
      " một người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người thổi người th.\n",
      "Ng cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho c.\n",
      " cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho.\n",
      "Ễ cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho ch.\n",
      "U cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho cho ch.\n",
      "\n",
      "Iteration: 3001, Loss: 1.819587\n",
      "\n",
      "9/7̣●@̀̃●@@̣̃●●@̣̃●●@̣̃●●@@@●●@@̣̃●●@@@̃●@̣̀̃●*̣̀̃●@@̣̃●●@@@̃●@@̣̃●●@@@●●@@̣̃●●@@̃●●̣̣̀●*@@̣̃●●@@̃●●̀@̃̃●@@̣̃●●@̣̃●●@̣̃●●@@̣̃●*̣̀̃●●@̣̃̃●@@̣̃●●@̣̃●●@@̃̃●@@̣̃●●@̣̃●●@@@●●@@̣̃●*@@@̃●@@̣̃●@@̣̃●●@@@̃●*@@@.\n",
      "C trong những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những .\n",
      "I trong những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những .\n",
      "I đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đầ.\n",
      ".\n",
      "N những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những những .\n",
      " đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần tho người đần.\n",
      "\n",
      "Iteration: 3201, Loss: 1.733127\n",
      "\n",
      " chuyện thương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chư.\n",
      " thương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chư.\n",
      "Ng chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương c.\n",
      "O chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ chỉ ch.\n",
      "Mình chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương.\n",
      " chỉ thế chuyện thương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương ch.\n",
      "I chính chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chương chư.\n",
      "\n",
      "Iteration: 3401, Loss: 1.777380\n",
      "\n",
      "I cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một nhữn.\n",
      "Chân tràng cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người.\n",
      "Ệ hiện tràng cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho ngư.\n",
      "Ột những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người m.\n",
      "Ột những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người m.\n",
      " cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những.\n",
      "M cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một những cho người một nhữn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration: 3601, Loss: 2.177989\n",
      "\n",
      "Hục chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện.\n",
      "Hà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho ngh.\n",
      "Cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe c.\n",
      " thơ thơ nhà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện .\n",
      " cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe .\n",
      "Ẽ cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe.\n",
      " thơ thơ thơ nhà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chuyện bà cho nghe chu.\n",
      "\n",
      "Iteration: 3801, Loss: 1.822600\n",
      "\n",
      "À thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên th.\n",
      "A thương thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể n.\n",
      "N thương thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể n.\n",
      " được thể thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể .\n",
      "Ên được thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nh.\n",
      "Hi chu thương thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể .\n",
      " chu thương thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể thể nhiên thể th.\n",
      "\n",
      "Iteration: 4001, Loss: 1.939389\n",
      "\n",
      " một thân thị là là như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như .\n",
      " là như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như .\n",
      ".\n",
      "M như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như nh.\n",
      "Ng là như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như nh.\n",
      " là như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như .\n",
      "Ng là như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như như nh.\n",
      "\n",
      "Iteration: 4201, Loss: 1.887669\n",
      "\n",
      "Nh thì học” là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được .\n",
      " mình thì học” là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là đư.\n",
      "Hải thì học” là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được.\n",
      " thì học” là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được nh.\n",
      "À cho đề thì học” là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là.\n",
      "I nhưng thì học” là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là .\n",
      " là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được như là được.\n",
      "\n",
      "Iteration: 4401, Loss: 2.037506\n",
      "\n",
      "H chú chú chim người thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật.\n",
      " thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật.\n",
      " thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật.\n",
      " người thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thậ.\n",
      "Ng thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật th.\n",
      "Ớc người thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật t.\n",
      "N đẹp chú chú chim người thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật thật .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-86d113d0fa5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix_to_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_to_ix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-86d113d0fa5f>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(examples, ix_to_char, char_to_ix, num_iterations, n_a, num_sampling, verbose)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# Perform one optimization step: Forward-prop -> Backward-prop -> Clip -> Update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m# Choose a learning rate of 0.01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# Use a latency trick to keep the loss smooth. It happens here to accelerate the training.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-bdbb00bac7b5>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(X, Y, a_prev, parameters, optimizer, criterion)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Forward propagate through time (≈1 line)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_prev\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mrnn_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-af562dd76cf4>\u001b[0m in \u001b[0;36mrnn_forward\u001b[1;34m(X, Y, a0, parameters)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msequence_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Run one step forward of the RNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_step_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Update the loss by substracting the cross-entropy term of this time-step from it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-1ed78ed41a87>\u001b[0m in \u001b[0;36mrnn_step_forward\u001b[1;34m(parameters, a_prev, x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrnn_step_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mWax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWaa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWya\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWax\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mWaa\u001b[0m\u001b[1;33m@\u001b[0m \u001b[0ma_prev\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWya\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#     y = softmax1d(z)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def model(examples, ix_to_char, char_to_ix, num_iterations = 35000, n_a = 50, num_sampling = 7, verbose = False):\n",
    "    \"\"\"\n",
    "    Trains the model and generates text. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve n_x and n_y from vocab_size\n",
    "    n_x, n_y = vocab_size, vocab_size\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters(n_a, n_x, n_y)\n",
    "    optimizer = optim.Adam(parameters, lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for item in parameters:\n",
    "        print(item.shape)\n",
    "    # Initialize loss (this is required because we want to smooth our loss)\n",
    "#     loss = get_initial_loss(vocab_size, num_sampling)\n",
    "        \n",
    "    # Shuffle list of all dinosaur names\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(examples)\n",
    "    \n",
    "    # Initialize the hidden state \n",
    "    a_prev = torch.zeros((n_a, 1))\n",
    "    \n",
    "    # Optimization loop\n",
    "    for j in range(num_iterations):\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Set the index `idx` (see instructions above)\n",
    "        idx = j % len(examples)\n",
    "        \n",
    "        # Set the input X (see instructions above)\n",
    "        single_example = examples[idx]\n",
    "        single_example_chars = [c for c in single_example]\n",
    "        single_example_ix = [char_to_ix[c] for c in single_example_chars]\n",
    "        X = [None]+single_example_ix\n",
    "        \n",
    "        # Set the labels Y (see instructions above)\n",
    "        ix_newline = char_to_ix['.']\n",
    "        Y = X[1:] + [ix_newline]\n",
    "        if verbose == True and j < 10:\n",
    "            print(single_example, \" X = \", X, \"\\n\", \"Y =       \", Y, \"\\n\")\n",
    "        \n",
    "        # Perform one optimization step: Forward-prop -> Backward-prop -> Clip -> Update parameters\n",
    "        # Choose a learning rate of 0.01\n",
    "        loss, a_prev = optimize(X, Y, a_prev, parameters, optimizer, criterion)\n",
    "\n",
    "        # Use a latency trick to keep the loss smooth. It happens here to accelerate the training.\n",
    "#         loss = smooth(loss, curr_loss.detach())\n",
    "        \n",
    "        \n",
    "        if j % len(examples) == 0:\n",
    "            np.random.shuffle(examples)\n",
    "            \n",
    "        # Every 2000 Iteration, generate \"n\" characters thanks to sample() to check if the model is learning properly\n",
    "        if j % 200 == 1:\n",
    "            print('\\nIteration: %d, Loss: %f' % (j, loss) + '\\n')\n",
    "            \n",
    "            # The number of dinosaur names to print\n",
    "            for name in range(num_sampling):\n",
    "                # Sample indices and print them\n",
    "                sampled_indices = sample(parameters)\n",
    "                last_sentence = get_sample(sampled_indices)\n",
    "                print(last_sentence)\n",
    "\n",
    "    return parameters\n",
    "\n",
    "parameters = model(sents, ix_to_char, char_to_ix, 35000, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "rnn = nn.RNN(vocab_size, 50, max_str_len, batch_first=True)\n",
    "parameters = list(rnn.parameters())\n",
    "len(parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
